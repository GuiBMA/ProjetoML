\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage[utf8]{inputenc}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
    
\begin{document}

\title{Lung Cancer Survival Prediction with Machine Learning: An Applied Project%
\thanks{This research received no specific grant from any funding agency in the public, commercial, or not-for-profit sectors.}}

\author{\IEEEauthorblockN{Guilherme Barros\\Ian Amoedo\\João Campelo}
\IEEEauthorblockA{\textit{Data Science and AI} \\
\textit{IBMEC-RJ Barra da Tijuca}\\
Rio de Janeiro, Brazil \\
jvguimaraescampelo@gmail.com\\
ianamoedobe@gmail.com\\
guibma@hotmail.com\\
https://github.com/GuiBMA/ProjetoML}}
\maketitle

\begin{abstract}
Lung cancer remains the leading cause of cancer mortality worldwide, accounting for roughly one in five cancer‐related deaths and placing a multibillion-dollar burden on health systems. Despite therapeutic advances such as targeted therapies and immuno-oncology, mean survival still hovers around fourteen months for advanced-stage patients because late diagnosis and heterogeneous tumour biology limit treatment efficacy. In response, this work develops an end-to-end machine-learning pipeline to predict patient survival, comparing traditional logistic regression with tree-based ensembles under severe class imbalance. Leveraging a registry‐scale data set ($\approx$ 890 k records) and rigorous cross-validation, the pipeline integrates automated feature engineering, resampling techniques, and probability-threshold optimisation. Results show only marginal gains (AUC $\approx$ 0.55) for Random Forests, underscoring data-quality constraints, the paucity of molecular markers, and the imperative for richer multimodal clinical features. Nevertheless, the study delivers a replicable analytics framework, quantifies the incremental value of advanced models, and provides actionable managerial insights for precision-medicine initiatives—namely, prioritising data curation, expanding genomic profiling, and aligning predictive outputs with care-pathway decision points to maximise return on analytics investment.
\end{abstract}

\begin{IEEEkeywords}
lung cancer, survival prediction, machine learning, class imbalance, healthcare analytics
\end{IEEEkeywords}

\section{Introduction}
Lung cancer represents a critical global health challenge, accounting for the highest share of cancer-related deaths and imposing substantial operational and financial strain on healthcare ecosystems.  

Prognostic uncertainty hampers timely escalation of care, often leading to sub-optimal utilisation of high-cost therapeutics and diagnostics. Accurate survival prediction therefore functions as a strategic enabler, allowing clinicians to segment patient cohorts, triage interventions, and allocate limited resources with greater precision.  

Emerging evidence indicates that machine-learning (ML) models—particularly ensemble architectures—can synthesise disparate clinical, demographic, and molecular signals, revealing non-linear risk interactions that conventional statistical paradigms routinely overlook. By operationalising these advanced analytics within a robust decision-support framework, healthcare organisations can drive value-based outcomes, reduce unwarranted variability in care pathways, and accelerate the transition toward personalised oncology.

\section{Theoretical Framework}
Logistic regression has long dominated binary clinical-prediction workflows because of its transparency, ease of calibration, and straightforward inferential properties. However, its core assumption of linear log-odds relationships curtails its ability to capture latent, higher-order feature synergies that often underlie complex oncological outcomes.  

Ensemble learners—most prominently Random Forests \cite{Breiman2001}—systematically overcome this limitation by aggregating decorrelated decision trees, thereby modelling non-monotonic interactions, dampening variance through bootstrap re-sampling, and maintaining robustness against noisy covariates. Contemporary meta-analyses, such as the systematic review by Didier \textit{et al.} \cite{Didier2024}, demonstrate that migrating from linear baselines to ML ensembles yields mean AUC uplifts of approximately 0.08, signalling meaningful incremental discriminative power.  

Nevertheless, the predictive landscape is further complicated by severe class imbalance—only \textasciitilde22\% survivors in our registry—which inflates nominal accuracy and disguises minority-class misclassification. This imbalance mandates the deployment of specialised counter-measures, including synthetic oversampling, cost-sensitive loss functions, and probability-threshold optimisation as advocated by He and Garcia \cite{He2009}. Within such a calibrated evaluation regime, composite metrics—sensitivity, specificity, F\textsubscript{$\beta$}-score, and ROC-AUC—collectively furnish a multidimensional performance scorecard capable of exposing both algorithmic strengths and residual blind spots.


\section{Methodology}
\subsection{Data Set}
A simulated registry of 890,000 de-identified lung-cancer cases aggregates multi-axis attributes—demographics (age, sex, ethnicity), lifestyle indicators (smoking pack-years, alcohol intake, occupational exposure), comorbidity flags (COPD, hypertension, diabetes, cardiovascular disease), treatment vectors (surgery, chemo-radiotherapy, immunotherapy, targeted therapy), and TNM stage—mapped to the binary outcome \textit{Survived}. Survivorship constitutes roughly 22\% of observations ($\approx$ 196 k records), introducing structural class imbalance. Enterprise-grade data-quality audits reveal 3.4\% aggregate missingness, rectified via listwise deletion for numerical robustness, and categorical feature cardinality was harmonised through one-hot encoding to ensure model-ready, schema-compliant tensors.

\subsection{Pre-processing}
Missing values—representing 3.4\% of the total feature space—were expunged via listwise deletion after confirming that the missingness mechanism was MCAR, thus safeguarding statistical validity without introducing imputation bias. Categorical predictors were vectorised through one-hot encoding, thereby converting nominal levels into sparse, mutually exclusive indicator columns while preserving interpretability for downstream SHAP analyses. Continuous attributes were standardised using z-score normalisation; critically, scaling parameters ($\mu$, $\sigma$) were fitted exclusively on the training partition and subsequently applied to validation and test folds, eliminating information leakage and ensuring that performance estimates reflect true out-of-sample generalisability.

\subsection{Experimental Design}
The corpus was partitioned via a stratified 80/20 split, preserving minority-class prevalence across folds and sequestering the 20\,\% hold-out tranche as an immutable audit set. Hyper-parameter optimisation executed on the training tranche through nested 5-fold cross-validation. Three algorithmic baselines entered the benchmarking pipeline:

\begin{enumerate}
    \item \textbf{Model 1—Baseline Logistic Regression:} vanilla logistic regression with L2 regularisation.
    \item \textbf{Model 2—Random Forest:} 100-tree ensemble leveraging out-of-bag error for intrinsic validation.
\end{enumerate}

For Model 3, decision thresholds of 0.5 and 0.3 were additionally profiled to interrogate sensitivity–specificity trade-offs.

\section{Plots}
\subsection{Box Plot}
The boxplot presented in Figure \ref{fig:RplotBox} illustrates the distribution of ages across two groups of patients: those who survived (labeled “Yes”) and those who did not survive (labeled “No”). The analysis of age as a predictor of lung-cancer survival reveals that the non-surviving group tends to have a higher median age (around 60 years), represented by the higher central line within the red box. In contrast, the surviving group (green box) shows a relatively lower median age, approximately 50 years, with a less pronounced spread. This suggests that younger patients have a slightly better survival rate, a finding aligned with existing literature where age is often inversely related to cancer prognosis. Furthermore, both groups exhibit a significant spread of ages, as shown by the whiskers of the boxes, indicating variability within each survival-status cohort. However, the distribution for the non-surviving group is wider, reflecting a higher variance in age. Outliers are also present in both groups, signifying the presence of extreme age values that deviate from general trends. Overall, this boxplot reinforces the hypothesis that age may serve as a predictive factor, although it is likely influenced by a range of additional clinical variables.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=.9\linewidth]{BoxPlot.png}
    \caption{Age distribution by survival status.}
    \label{fig:RplotBox}
\end{figure}

\subsection{ROC Curve}
The ROC curve in Figure \ref{fig:RplotROC} compares the performance of three models—Original Logistic Regression, Random Forest, and Balanced Logistic Regression—in predicting lung-cancer survival. The graph plots sensitivity (true-positive rate) against 1-specificity (false-positive rate), providing a comprehensive visual comparison of model performance across various threshold values.

From the plot, it is evident that all three models show relatively similar performance, with their curves closely overlapping. The Random Forest model (red curve) demonstrates a marginally better separation from the diagonal line (representing random guessing) compared to both Logistic Regression variants. However, the difference in AUC among the models is minimal, reinforcing the notion that, despite incorporating more advanced ML methods, predictive power remains constrained. This outcome is consistent with the reported AUC values, where none of the models achieved substantial discrimination between survival classes, reflecting challenges posed by class imbalance and limited predictive features. The Balanced Logistic Regression (green curve) appears to slightly outperform the original Logistic Regression (blue curve) in sensitivity, suggesting that addressing class imbalance may improve the model’s ability to correctly identify survivors, albeit at the cost of specificity.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=.9\linewidth]{CurvaROC.png}
    \caption{ROC curve comparison across models.}
    \label{fig:RplotROC}
\end{figure}

\subsection{Histogram}
Figure \ref{fig:RplotHist} shows the age distribution of patients in the dataset. The data are spread across a wide range, with a clear central peak between 50 and 70 years of age. This suggests that the majority of patients in this cohort are middle-aged to elderly, consistent with the prevalence of lung cancer in older populations. The distribution appears roughly symmetric with a slight skew toward older ages, as the number of patients gradually decreases beyond 70 years.

The histogram also reveals that there are fewer patients in extreme age groups, such as those below 30 or above 90, with both tails of the distribution showing sparse frequency. This pattern reflects general trends in lung-cancer diagnoses, where incidence tends to increase with age. Understanding the age distribution is crucial for survival prediction, as age is a known factor influencing cancer outcomes.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=.9\linewidth]{DitribuicaoPorIdade.png}
    \caption{Patient age distribution.}
    \label{fig:RplotHist}
\end{figure}

\section{Results and Discussion}
Table \ref{tab:performance} compares four modelling strategies evaluated on the lung‐cancer survival cohort: Original Logistic Regression, Random Forest, and two Balanced Logistic Regression variants (decision thresholds 0.5 and 0.3). Key metrics include accuracy (Acc.), sensitivity (Sens.), specificity (Spec.), and area under the ROC curve (AUC).

\begin{table}[htbp]
\caption{Test-set Performance Comparison}
\begin{center}
\begin{tabular}{|l|c|c|c|c|}
\hline
\textbf{Model} & \textbf{Acc.} & \textbf{Sens.} & \textbf{Spec.} & \textbf{AUC}\\
\hline
Logistic (orig.)      & 0.78 & 0.00 & 1.00 & 0.50\\
Random Forest         & 0.78 & 0.15 & 0.96 & 0.55\\
Balanced Logit (0.5)  & 0.60 & 0.60 & 0.60 & 0.50\\
Balanced Logit (0.3)  & 0.50 & 0.80 & 0.45 & 0.50\\
\hline
\end{tabular}
\label{tab:performance}
\end{center}
\end{table}

Random Forests delivered marginal uplift in AUC and recall relative to the linear baseline, achieving moderate sensitivity (0.15) without catastrophic accuracy loss. Balanced Logistic Regression, while elevating survivor detection (Sens.\ up to 0.80 at the 0.3 threshold), sacrificed specificity and overall accuracy, demonstrating the classical precision–recall trade-off inherent in imbalance-correction tactics.

The sub-par AUC values (0.55) across all configurations underscore limited signal fidelity in routine clinical parameters. Absent molecular markers, radiomics, and performance-status metrics, the models lack the discriminatory granularity required for high-stakes prognostics. Future research agendas should prioritise multimodal feature acquisition and cost-sensitive boosting frameworks to counteract imbalance. Additionally, finer-grained staging variables and genomic covariates could unlock actionable accuracy gains, while interpretability layers (e.g., SHAP) will be essential for clinical trust and adoption.

\section{Conclusion}
Machine-learning ensembles yielded only marginal gains in lung-cancer survival prediction; their effectiveness is presently capped by sparse, imbalanced feature sets that fail to capture the underlying biological heterogeneity. Without richer inputs, even sophisticated architectures cannot deliver the discriminative power demanded by precision-oncology workflows.  

To enhance prognostic accuracy and clinical relevance, subsequent research must prioritise the integration of high-dimensional genomic, molecular, and radiomic data. Equally vital is the deployment of interpretability layers—such as SHAP or LIME—that render model outputs transparent to multidisciplinary tumour boards and bolster stakeholder confidence. Robust external validation and cost-sensitive learning strategies are indispensable for addressing class imbalance and ensuring generalisability across diverse patient populations.  

Looking ahead, the accelerating evolution of deep-learning paradigms, coupled with expanding multimodal data repositories, positions the field for substantive breakthroughs. By aligning methodological innovation with rigorous governance and real-world evidence, future models can transition from academic proofs of concept to actionable decision-support tools, ultimately advancing the mandate of personalised oncology and improving patient outcomes.

\begin{thebibliography}{00}
\bibitem{Breiman2001} L.~Breiman, ``Random forests,'' \textit{Machine Learning}, vol.~45, no.~1, pp.~5--32, 2001.
\bibitem{Didier2024} A.~J.~Didier \textit{et al.}, ``Application of machine learning for lung-cancer survival prognostication—a systematic review and meta-analysis,'' \textit{Frontiers in Artificial Intelligence}, vol.~7, 2024.
\bibitem{He2009} H.~He and E.~A.~Garcia, ``Learning from imbalanced data,'' \textit{IEEE Trans. Knowl. Data Eng.}, vol.~21, no.~9, pp.~1263--1284, 2009.
\end{thebibliography}

\end{document}
